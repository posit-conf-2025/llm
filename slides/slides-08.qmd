---
title: Tool Calling
subtitle: Programming with LLM APIs<br>A Beginner's Guide in R and Python
author: <code>posit::conf(2025)</code>
date: 2025-09-16

editor:
  render-on-save: true
---

# [Tool calling]{.hidden} {.no-invert-dark-mode background-image="assets/robot-tools.jpg" background-size="cover" background-position="center"}

::: hidden
A robot wearing a tool belt, selects a tool from a wall of futuristic space tools. A sign above the wall reads "Tools".
:::

## Recall: How do LLMs work? {.center}

::: incremental
1. You write some words

2. The LLM writes some more words

3. You _use those words_
:::

::: fragment
_On their own, can LLMs... access the internet? send an email? interact with the world?_
:::

## Let's try it

```{.r}
library(ellmer)

chat <- chat("openai/gpt-4.1-nano")

chat$chat("What's the weather like in Atlanta, GA?")
chat$chat("Who are the keynote speakers at posit::conf(2025)?")
chat$chat("What day is it?")
```

::: mt3
```{.python}
import chatlas

chat = chatlas.Chat(model="openai/gpt-4.1-nano")
chat.chat("What's the weather like in Atlanta, GA?")
chat.chat("Who are the keynote speakers at posit::conf(2025)?")
chat.chat("What day is it?")
```
:::

::: notes
Run these in the terminal.

Ask: how could we get the model to know these answers? Let's start with the easiest one: what day is it?

Answer: we could just tell it in the system prompt.

What about keynote speakers? We could include that in the system prompt too. But what if the schedule changes?

What about the weather? The model can't know that because it's not connected to the internet.
:::

## Tools {.center}

a.k.a. _functions_, _tool calling_ or _function calling_

::: incremental
* Bring real-time or up-to-date information to the model

* Letting the model interact with the world<sup>*</sup>
:::

::: notes
Tools are extra capabilities that you give to the LLM, like the ability to search the posit::conf(2025) schedule.
These capabilities are things that the model can't do on its own.
The goal is let the model pull in real-time, or up-to-date, or high-quality information as needed, depending on the conversation.

They can also give the model new abilities to take action on behalf of the user.
:::

# Chatbot Systems

## {.center style="text-align: center" transition="fade"}

![](assets/chat-systems-user-06.excalidraw.svg)

::: footer
user vs. programmer
:::

## {.center style="text-align: center" transition="fade"}

![](assets/chat-systems-user-07.excalidraw.svg)


## {.center style="text-align: center" transition="fade"}

![](assets/chat-systems-user-08.excalidraw.svg)


## {.center style="text-align: center" transition="fade"}

![](assets/chat-systems-user-16.excalidraw.svg)


## {.center style="text-align: center" transition="fade"}

![](assets/chat-systems-user-17.excalidraw.svg)


## {.center style="text-align: center" transition="fade"}

![](assets/chat-systems-user-18.excalidraw.svg)


## {.center style="text-align: center" transition="fade"}

![](assets/chat-systems-user-19.excalidraw.svg)


## {.center style="text-align: center" transition="fade"}

![](assets/chat-systems-user-20.excalidraw.svg)


## {.center style="text-align: center" transition="fade"}

![](assets/chat-systems-user-21.excalidraw.svg)


## How do tool calls work? {.center}

What should I wear to posit::conf(2025) in Atlanta?

::: notes
So how do we connect the LLM to the code that this data scientist has written (or could write) to give the model new abilities?
:::

## Human in the loop {.center}

👨‍💻 [_demos/18_manual-tools/app.R]{.code .b .purple}

## Wait... I can write code! {.center}

👨‍💻 [_demos/19_tools/19_weather-tool.R]{.code .b .purple}

👨‍💻 [_demos/19_tools/19_weather-tool.py]{.code .b .purple}

## {.center style="text-align: center" transition="fade"}

![](assets/tools-how-it-works-01.excalidraw.svg)

::: notes
Zooming out again, the conversation starts with a user sending a message to the chatbot.

In this case, the user asks the model whether they can go to the pool today.
(I live in Atlanta, GA.)

How much does the model know about the weather in Atlanta, GA?

**What's the weather like today in Atlanta, GA?**

> I'm unable to provide real-time weather updates. For the latest weather forecast in Atlanta, GA, please check a trusted weather service such as
the National Weather Service, Weather.com, or a weather app on your device.

**Go ahead and guess**

> Sure! Since it's July in Atlanta, GA, you can generally expect hot and humid weather. Temperatures might range from the mid-80s to mid-90s
Fahrenheit (around 29-35°C). There could also be some afternoon thunderstorms or showers, which are common during summer months in Georgia. Keep a
fan or air conditioning handy if you're indoors, and stay hydrated!
:::

## {.center style="text-align: center" transition="fade"}

![](assets/tools-how-it-works-02.excalidraw.svg)

::: notes
Now imagine we've told the LLM that it has access to a tool called `get_weather()`.
Knowing that it 1) needs to know the weather in Atlanta and 2) it doesn't know the weather in Atlanta, GA; the model decides to use the weather tool.

It sends back a message that includes a tool call, basically instructions to call the `get_weather()` function with the argument `30303`.
Notice that the model _does know_ that Atlanta, GA is in the 30303 ZIP code.
:::

## {.center style="text-align: center" transition="fade"}

![](assets/tools-how-it-works-03.excalidraw.svg)

::: notes
The programmer can then take that message from the LLM with the instructions to call the tool and they go off and run the code that that satisfies the tool request, in this case querying the weather API for the weather in 30303 because that has been a stable fact for a long time.
:::

## {.center style="text-align: center" transition="fade"}

![](assets/tools-how-it-works-04.excalidraw.svg)

::: notes
The weather API sends back some data:

* The forecast is mostly sunny
* High of 98ºF
* Low of 78ºF
:::

## {.center style="text-align: center" transition="fade"}

![](assets/tools-how-it-works-05.excalidraw.svg)

::: notes
The programmer sends that data back to the LLM.
Note that it's often in a pretty raw format, like JSON.
Not the kind of thing you'd want to read directly unless you're the kind of person who likes reading computer data formats.
:::

## {.center style="text-align: center" transition="fade"}

![](assets/tools-how-it-works-06.excalidraw.svg)

::: notes
The LLM doesn't mind JSON though, so it reads the data and generates a response that _incorporates_ the data from the tool call.
:::

## {.center style="text-align: center" transition="fade"}

![](assets/tools-how-it-works-07.excalidraw.svg)

## Recap: Tool definitions in R

```{.r code-line-numbers="|1|2|3|4-11"}
tool_get_weather <- tool(
  tool_fn,
  description = "How and when to use the tool",
  arguments = list(
    .... = type_string(),
    .... = type_integer(),
    .... = type_enum(
      c("choice1", "choice2"),
      required = FALSE
    )
  )
)
```

## Recap: Tool definitions in Python

```{.python}
def get_weather(lat, lon):
    return NWS.GetCurrentForecast(lat, lon)
```

## Recap: Tool definitions in Python

```{.python code-line-numbers="1-1"}
def get_weather(lat: float, lon: float):
    return NWS.GetCurrentForecast(lat, lon)
```

## Recap: Tool definitions in Python

```{.python code-line-numbers="2-11"}
def get_weather(lat: float, lon: float):
    """
    Get forecast data for a specific latitude and longitude.

    Parameters
    ----------
    lat : str
        Latitude of the location.
    lon : str
        Longitude of the location.
    """
    return NWS.GetCurrentForecast(lat, lon)
```

# Your Turn `20_quiz-game-2` {.slide-your-turn}

1. I've given you a function that plays a sound when called.

1. Your job: teach the model to play sounds in the Quiz Show game we made earlier today.

1. _You can use your prompt or switch `_exercises` &rarr; `_solutions` to use ours._

{{< countdown 6:00 left=0 bottom="-2em" >}}

::: notes
Follow up question: why send a string back to the LLM that says the sound was played?
:::

# [Tool UI]{.hidden} {.no-invert-dark-mode background-image="assets/robot-tools-shinychat.jpg" background-size="cover" background-position="center"}

::: hidden
A robot is standing in front of a display case, pointing at a holographic interface showing various tools and options. The robot appears to be selecting a tool from the interface.
:::


## Your Turn `21_quiz-game-3` {.slide-your-turn}

1. Step 1

1. Step 2

1. Step 3

{{< countdown 8:00 left=0 bottom="-2em" >}}

## Your Turn `22_quiz-game-4` {.slide-your-turn}

1. Step 1

1. Step 2

1. Step 3

{{< countdown 8:00 left=0 bottom="-2em" >}}

## Your Turn `23_quiz-game-5` {.slide-your-turn}

1. Step 1

1. Step 2

1. Step 3

{{< countdown 8:00 left=0 bottom="-2em" >}}
